{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b47cfb64-dddf-40c7-bdbb-a95b3455dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from multiprocessing import cpu_count\n",
    "max_cpu = cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4d5903-62eb-4ca1-8701-63014579f736",
   "metadata": {},
   "source": [
    "# Homework (Lecture 9)\n",
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2610eb4-c6b5-4f80-bfa3-cd19fe97d629",
   "metadata": {},
   "source": [
    "### Part (a)\n",
    "\n",
    "$X_i \\sim Exp(\\lambda), \\lambda >0 $\n",
    "\n",
    "$\\displaystyle \\sum_{i=1}^{100} \\log(\\lambda e^{-\\lambda X_i}) \\cdot 1(X_i > 0) = \\sum_{i=1}^{100} \\log(\\lambda e^{-\\lambda X_i}) = 100 log(\\lambda) - \\lambda \\sum_{i=1}^{100} X_i$\n",
    "\n",
    "$\\frac{\\partial}{\\partial \\lambda} ( 100 log(\\lambda) - \\lambda \\sum_{i=1}^{100} X_i) = \\frac{100}{\\lambda} - \\sum_i X_i \\Rightarrow \\hat{\\lambda}^{MLE} = \\displaystyle \\frac{1}{\\bar{X}}$\n",
    "\n",
    "Under mild regularity conditions, the asymptotic variance of an MLE estimator can be shown to be $\\sqrt{n}(\\hat{\\beta}_n^{MLE} - \\beta) \\overset{d}{\\to} N(0,\\Sigma^{-1})$ where $\\Sigma = \\displaystyle \\frac{1}{I(\\lambda)}$, $I(\\lambda) = \\displaystyle -E[\\frac{\\partial^2 \\log{f(X;\\lambda)}}{\\partial \\lambda^2}]$ and $f(X;\\lambda) = \\lambda e^{-\\lambda x}$\n",
    "\n",
    "$\\displaystyle \\frac{\\partial}{\\partial \\lambda} \\log{\\lambda e^{-\\lambda x}} = \\frac{\\partial}{\\partial \\lambda} (log{\\lambda} -\\lambda x) = \\frac{1}{\\lambda} - x \\Rightarrow \\frac{\\partial}{\\partial \\lambda} (\\frac{1}{\\lambda} - x) = -\\frac{1}{\\lambda^2} \\Rightarrow I(\\lambda) = E[\\frac{1}{\\lambda^2}]$\n",
    "\n",
    "Therefore the asymptotic variance of $\\hat{\\lambda}^{MLE}$ can be expressed as $E[\\frac{1}{\\lambda^2}]^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c73ae5-64b4-40d2-a0e8-46de4b3521e5",
   "metadata": {},
   "source": [
    "### Part (b)\n",
    "\n",
    "Given $\\hat{\\lambda}^{MLE}$, we can use the estimated CDF of X to find $\\displaystyle P(X \\le 1) = 1- e^{-\\lambda \\cdot 1} = 1- e^{-\\hat{\\lambda}^{MLE}} = 1- e^{-\\frac{1}{\\bar{X}}}$ = 0.918."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a5245-4959-40d3-a0e1-866dc9fe4221",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part (c)\n",
    "\n",
    "Applying the Delta Method, since we have $\\displaystyle \\sqrt{n} (\\frac{1}{\\bar{X}} - \\lambda) \\overset{d}{\\to} N(0, E[\\frac{1}{\\lambda^2}]^{-1})$, to construct a 95% CI for $P(X \\le 1)$, we can show that $\\displaystyle \\sqrt{n} (\\hat{P} - P) \\overset{d}{\\to} N(0, [g'(\\lambda)]^2 \\cdot \\Sigma^{-1}) = N(0, (e^{-2 \\lambda} \\cdot E[\\frac{1}{\\lambda^2}]^{-1} )$\n",
    "\n",
    "Now that we have the asymptotic variance of this estimator, we can construct a 95% CI: $\\hat{p} \\pm 1.96 \\times se(\\hat{p}) = 0.9179 \\pm 0.0.04022$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f1eaff-62ff-4dae-9db6-852e38440810",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part (d)\n",
    "\n",
    "$\\hat{P}(X \\le 1) = 0.8 \\Rightarrow \\frac{1}{n} \\sum_{i=1}^{100} 1(X \\le 1) = 0.8$. Since the sum of Bernoulli random variables follows a binomial distribution, we know the variance is $npq = (100)(0.8)(0.2) = 16$. By the CLT, we see that $\\hat{p}_n \\sim N(\\mu, \\frac{\\sigma^2}{n}) = N(0.8,0.16)$. As such, a 95% CI for $\\hat{p}_n$ is: $\\hat{p}_n \\pm 1.96 \\times se(\\hat{p}_n) = 0.8 \\pm 0.0784$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f20943-f5db-4bd1-8e81-82bf4d8c97e4",
   "metadata": {},
   "source": [
    "### Part (e)\n",
    "\n",
    "I would trust the one from Part (d) more since it makes fewer assumptions about the true distribution of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b04fc31-cad7-4bfe-b83f-d6ee93a08653",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "### Part (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "faf11c8f-6cf1-4ea4-92f7-16ad1c92656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DGP():\n",
    "    V = np.random.exponential(scale=2,size = 200)\n",
    "    X = 1 + V\n",
    "    epsilon = np.random.normal(0,np.sqrt(0.5),size=200)\n",
    "    Y = 2 + 2 * np.log(X) + epsilon\n",
    "    temp = np.sort(np.column_stack((X,Y)),axis=0)\n",
    "    X, Y = temp[:,0], temp[:,1]\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def gauss_kernel(u):\n",
    "    return (1/np.sqrt(2*np.pi)) * np.exp(-(u ** 2)/2)\n",
    "\n",
    "def LL(X,Y,x,h):\n",
    "    Z = np.column_stack((np.ones(X.shape[0]),X-x))\n",
    "    K = np.diag(gauss_kernel((X-x)/h))\n",
    "    m_vec = np.linalg.inv(Z.T @ K @ Z) @ Z.T @ K @ Y\n",
    "    return m_vec[0], m_vec[1]\n",
    "\n",
    "def NN(X,Y,x,k):\n",
    "    x_norm = np.abs(X-x)\n",
    "    t = np.column_stack((x_norm,Y))\n",
    "    m = (1/k) * np.sum(t[t[:, 0].argsort()][:k,1])\n",
    "    return m\n",
    "\n",
    "def loo_ll_cv(param):\n",
    "    X,Y = DGP()\n",
    "    err = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        m, delt_m = LL(np.delete(X,i),np.delete(Y,i),X[i],param)\n",
    "        y_hat = m + delt_m * X[i]\n",
    "        err += (y_hat - Y[i]) ** 2\n",
    "    return param, err\n",
    "\n",
    "def loo_nn_cv(param):\n",
    "    X,Y = DGP()\n",
    "    err = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        y_hat = NN(np.delete(X,i),np.delete(Y,i),X[i],param)\n",
    "        err += (y_hat - Y[i]) ** 2\n",
    "    return param, err\n",
    "\n",
    "def cv_min_param(fn,params):\n",
    "    with ThreadPool(max_cpu - 1) as pool:\n",
    "        output = pool.map(fn,params)\n",
    "    df = pd.DataFrame(output,columns=['Parameter','Total Error']).sort_values(by='Total Error')\n",
    "    min_param = df['Parameter'][0]\n",
    "    return min_param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "95f31b1e-b7b8-40e5-9248-88e724c4ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.linspace(0.1,1000,50)\n",
    "ll_param = cv_min_param(loo_ll_cv,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "6de4db8a-f983-43d8-bca2-2ec8c7acf5f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = np.linspace(1,200,50,dtype=int)\n",
    "nn_param = cv_min_param(loo_nn_cv,params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a57a3c0-a6d9-4816-99c4-37634a51b17d",
   "metadata": {},
   "source": [
    "Via calculation we find that $R_K = 0.2821$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "e8512b2d-b29e-4307-9e5d-e754d84653a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ll_sigma_sq(X,x,h,e):\n",
    "    return (np.sum(gauss_kernel((X-x)/h) * (e ** 2))) / (np.sum(gauss_kernel((X-x)/h)))\n",
    "\n",
    "def fx(X,x,h):\n",
    "    return (1/ (X.shape[0] * h)) * np.sum(gauss_kernel((X-x)/h))\n",
    "\n",
    "def ll_var(X,x,h,m,mdelt,y):\n",
    "    e = y - (m + mdelt * x)\n",
    "    return (0.2821 * ll_sigma_sq(X,x,h,e)) / fx(X,x,h)\n",
    "\n",
    "def ll_ci(X,Y,x,h):\n",
    "    m, delt_m = LL(X,Y,x,h)\n",
    "    y_hat = m + delt_m * x\n",
    "    var = ll_var(X,x,h,m,delt_m,y)\n",
    "    upper = y_hat + 1.96 * np.sqrt(var/(X.shape[0] * h))\n",
    "    lower = y_hat - 1.96 * np.sqrt(var/(X.shape[0] * h))\n",
    "    return y_hat, upper, lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "14e0576a-a72b-4446-a7e7-d53bee4ed55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgrid = np.arange(1,5.2,0.2)\n",
    "X,Y = DGP()\n",
    "    \n",
    "yhat = []\n",
    "upper = []\n",
    "lower = []\n",
    "for x in xgrid:\n",
    "    mid, up, lb = ll_ci(X,Y,x,ll_param)\n",
    "    yhat.append(mid)\n",
    "    upper.append(up)\n",
    "    lower.append(lb)\n",
    "    \n",
    "pd.DataFrame({'TrueX':X,'TrueY':Y}).to_csv('ll_true_data.csv',index=False)\n",
    "pd.DataFrame({'yhat':yhat,'upper':upper,'lower':lower}).to_csv('ll_ci.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9fb25d47-7a59-4217-88ee-e0dd05e18115",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgrid = np.arange(1,5.2,0.2)\n",
    "\n",
    "nn_mid = []\n",
    "for x in xgrid:\n",
    "    mid = NN(X,Y,x,nn_param)\n",
    "    nn_mid.append(mid)\n",
    "\n",
    "pd.DataFrame({'yhat':nn_mid}).to_csv('nn_pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07091d2-17cf-4522-a3fb-afd03ca1f017",
   "metadata": {},
   "source": [
    "### Part (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "6feff58d-3889-4165-a88f-5be5710eddda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m1_contain = 0\n",
    "m3_contain = 0\n",
    "m_all = 0\n",
    "for i in np.arange(1000):\n",
    "    try:\n",
    "        X,Y = DGP()\n",
    "        x=1\n",
    "        m, delt_m = LL(X,Y,x,ll_param)\n",
    "        y_hat = m + delt_m * x\n",
    "        mid, upper, lower = ll_ci(X,Y,x,ll_param)\n",
    "        if (y_hat <= upper) and (y_hat >= lower):\n",
    "            m1_contain += 1\n",
    "\n",
    "        x=3\n",
    "        m, delt_m = LL(X,Y,x,ll_param)\n",
    "        y_hat = m + delt_m * x\n",
    "        mid, upper, lower = ll_ci(X,Y,x,ll_param)\n",
    "        if (y_hat <= upper) and (y_hat >= lower):\n",
    "            m3_contain += 1\n",
    "        allin = True\n",
    "        for j in range(200):\n",
    "            m, delt_m = LL(X,Y,X[j],ll_param)\n",
    "            y_hat = m + delt_m * X[j]\n",
    "            if not (y_hat <= upper) and (y_hat >= lower):\n",
    "                allin=False\n",
    "                break\n",
    "        if allin:\n",
    "            m_all += 1\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "441e165b-94fa-454d-be57-97069e9cecf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(m1_contain)\n",
    "print(m3_contain)\n",
    "print(m_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a9007a-8028-4707-b113-61489e444667",
   "metadata": {},
   "source": [
    "The entire function is much less frequently in the confidence band than the individual points. This makes intuitive sense since point-wise confidence intervals are not equal to uniform. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f462fe06-3a60-49b5-905e-4d877f424f4e",
   "metadata": {},
   "source": [
    "### Part (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "3c2534a6-a20a-4a33-a311-8130d81b0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_DGP():\n",
    "    V = np.random.exponential(scale=2,size = 200)\n",
    "    X = 1 + V\n",
    "    epsilon = np.random.normal(0,np.sqrt(0.5),size=200)\n",
    "    Y = 2 + 2 * X + epsilon\n",
    "    temp = np.sort(np.column_stack((X,Y)),axis=0)\n",
    "    X, Y = temp[:,0], temp[:,1]\n",
    "    \n",
    "    return X.reshape(200,1), Y.reshape(200,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "521fb629-50bb-440c-ad3c-ba5a62a8d35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_contain = 0\n",
    "m3_contain = 0\n",
    "m_all = 0\n",
    "for i in np.arange(1000):\n",
    "    try:\n",
    "        X,Y = new_DGP()\n",
    "        x=1\n",
    "        m, delt_m = LL(X,Y,x,ll_param)\n",
    "        y_hat = m + delt_m * x\n",
    "        mid, upper, lower = ll_ci(X,Y,x,ll_param)\n",
    "        if (y_hat <= upper) and (y_hat >= lower):\n",
    "            m1_contain += 1\n",
    "\n",
    "        x=3\n",
    "        m, delt_m = LL(X,Y,x,ll_param)\n",
    "        y_hat = m + delt_m * x\n",
    "        mid, upper, lower = ll_ci(X,Y,x,ll_param)\n",
    "        if (y_hat <= upper) and (y_hat >= lower):\n",
    "            m3_contain += 1\n",
    "        allin = True\n",
    "        for j in range(200):\n",
    "            m, delt_m = LL(X,Y,X[j],ll_param)\n",
    "            y_hat = m + delt_m * X[j]\n",
    "            if not (y_hat <= upper) and (y_hat >= lower):\n",
    "                allin=False\n",
    "                break\n",
    "        if allin:\n",
    "            m_all += 1\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "43670d82-963f-4d29-817b-3e254c3a293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(m1_contain)\n",
    "print(m3_contain)\n",
    "print(m_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "dd74004a-2d7b-4eb5-bebf-3ea4c4b23657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS_CI(X,Y,x):\n",
    "    beta = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "    u = Y - X * beta\n",
    "    sigma_sq = np.sum(u ** 2) / Y.shape[0]\n",
    "    var = sigma_sq * np.linalg.inv(X.T @ X)\n",
    "    width = 1.96 * np.sqrt(var / Y.shape[0])\n",
    "    beta_lb = beta - width\n",
    "    beta_ub = beta + width\n",
    "    \n",
    "    y_hat_lb, y_hat_ub = x * beta_lb, x * beta_ub\n",
    "    return y_hat_lb, y_hat_ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "1a579efd-c87b-4829-8bf5-eec24d34d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_contain = 0\n",
    "m3_contain = 0\n",
    "m_all = 0\n",
    "\n",
    "for i in np.arange(1000):\n",
    "    X,Y = new_DGP()\n",
    "    x=1\n",
    "    beta = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "    yhat = x * beta\n",
    "    y_hat_lb, y_hat_ub = OLS_CI(X,Y,x)\n",
    "    if (yhat <= y_hat_ub) and (yhat >= y_hat_lb):\n",
    "        m1_contain += 1\n",
    "    \n",
    "    x=3\n",
    "    beta = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "    yhat = x * beta\n",
    "    y_hat_lb, y_hat_ub = OLS_CI(X,Y,x)\n",
    "    if (yhat <= y_hat_ub) and (yhat >= y_hat_lb):\n",
    "        m3_contain += 1\n",
    "    \n",
    "    allin = True\n",
    "    for j in range(X.shape[0]):\n",
    "        beta = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "        yhat = X[j] * beta\n",
    "        y_hat_lb, y_hat_ub = OLS_CI(X,Y,X[j])\n",
    "        if (yhat <= y_hat_ub) and (yhat >= y_hat_lb):\n",
    "            allin = False\n",
    "            break\n",
    "    if allin:\n",
    "        m_all += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "fae83681-8a3f-4891-9255-2852db6a26ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(m1_contain)\n",
    "print(m3_contain)\n",
    "print(m_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eee8c8-0e92-4590-b911-e48586456b68",
   "metadata": {},
   "source": [
    "The OLS estimator tends to be in the CI interval more frequently than the Local Linear estimator with this DGP. This is intuitive since the DGP itself is linear, meaning that the OLS estimator should be in the CI interval/band more consistently since it fits the population model better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd40e6-02e6-4e99-8fd7-e3a1ac4efa0f",
   "metadata": {},
   "source": [
    "# Homework (Lecture 11)\n",
    "\n",
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90c102e5-6dae-4caf-92d7-802c2f6ad40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31069796-eef1-413c-8309-2c75e02ff1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DGP():\n",
    "    X = np.concatenate((np.random.normal(2,1,size=(300,1)),\n",
    "                        np.random.normal(4,1,size=(300,1))),axis=1)\n",
    "    y = X.sum(axis=1) + np.random.normal(300)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=100, random_state=31)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def tree_cv(param):\n",
    "    X_train, X_test, y_train, y_test = DGP()\n",
    "    model = DecisionTreeRegressor(ccp_alpha = param, random_state=31)\n",
    "    cv_scores = cross_val_score(model,X_train,y_train,cv=5,scoring='neg_mean_squared_error')\n",
    "    return param, -cv_scores.sum()\n",
    "\n",
    "def rf_cv(param):\n",
    "    X_train, X_test, y_train, y_test = DGP()\n",
    "    model = RandomForestRegressor(max_features = param, n_jobs = -1, random_state=31)\n",
    "    cv_scores = cross_val_score(model,X_train,y_train,cv=5,scoring='neg_mean_squared_error')\n",
    "    return param, -cv_scores.sum()\n",
    "\n",
    "def boost_cv(param):\n",
    "    X_train, X_test, y_train, y_test = DGP()\n",
    "    model = GradientBoostingRegressor(max_leaf_nodes = param, random_state=31)\n",
    "    cv_scores = cross_val_score(model,X_train,y_train,cv=5,scoring='neg_mean_squared_error')\n",
    "    return param, -cv_scores.sum()\n",
    "\n",
    "def cv_min_param(fn,params):\n",
    "    with ThreadPool(max_cpu - 1) as pool:\n",
    "        output = pool.map(fn,params)\n",
    "    df = pd.DataFrame(output,columns=['Parameter','MSE']).sort_values(by='MSE')\n",
    "    min_param = df['Parameter'][0]\n",
    "    return min_param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e7d1ae7-7835-43e9-a616-f41dcc2eb667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = np.linspace(0,1,100)\n",
    "tree_best = cv_min_param(tree_cv,params)\n",
    "tree_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7817743-9caa-495f-a90d-453b97b9c2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = np.linspace(1,1000,100,dtype=int)\n",
    "rf_best = cv_min_param(rf_cv,params)\n",
    "rf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ce828f8-a3da-4a2b-a4dc-193f9834fb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = np.linspace(2,200,100,dtype=int)\n",
    "boost_best = cv_min_param(boost_cv,params)\n",
    "boost_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d354442-5f9c-4e83-89ed-e600347098c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training optimal models\n",
    "X_train, X_test, y_train, y_test = DGP()\n",
    "\n",
    "tree = DecisionTreeRegressor(ccp_alpha = tree_best, random_state=31).fit(X_train,y_train)\n",
    "rf = RandomForestRegressor(max_features = rf_best, n_jobs = -1, random_state=31).fit(X_train,y_train)\n",
    "boost = GradientBoostingRegressor(max_leaf_nodes = boost_best, random_state=31).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c292d44e-a853-4e0f-8f7e-c739e675e572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree:\n",
      "0.2567916097552045\n",
      "RF:\n",
      "0.15254765570278406\n",
      "Boost:\n",
      "0.12052677166231912\n"
     ]
    }
   ],
   "source": [
    "print('Tree:')\n",
    "print(mean_squared_error(y_test, tree.predict(X_test)))\n",
    "\n",
    "print('RF:')\n",
    "print(mean_squared_error(y_test, rf.predict(X_test)))\n",
    "\n",
    "print('Boost:')\n",
    "print(mean_squared_error(y_test, boost.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f78ba-ce85-413a-8b8a-515fa173050e",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "### Part (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "68f03da3-d61a-4c68-a6dd-b8b2b83d9de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('penn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a80616e-bb67-4292-b7a2-468d33e07b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df.loc[(df['tg'] == 0) | (df['tg'] == 4)].iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8f7620-9064-46c6-b9cd-d391f055af57",
   "metadata": {},
   "source": [
    "### Part (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2812175e-f53c-4b62-aef1-c0249ff71814",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(sub_df['inuidur1']).to_numpy()\n",
    "D = np.where(sub_df['tg']==4,1,0).reshape(sub_df.shape[0],1)\n",
    "W = sub_df[['female', 'black', 'hispanic', 'othrace','agelt35', 'agegt54']].to_numpy()\n",
    "X = np.concatenate((D,W),axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd69894-2cf8-47c5-bacb-27b94590b400",
   "metadata": {},
   "source": [
    "### Part (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c6394e-5d50-45b9-9107-4cba1d9670d1",
   "metadata": {},
   "source": [
    "$E[Y | D=0, W] = f(W)$ and $E[Y | D=1, W] = g(W)$. Therefore, since $D \\in \\{0,1\\}$, we can say $E[Y | D, W] = f(W) + D(g(W) - f(W)) \\Rightarrow \\beta_0 (W) + D \\beta_1 (W)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb30d4f-5bfe-4739-ba3d-13a5ab42ac2a",
   "metadata": {},
   "source": [
    "### Part (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d650ab-9dbd-446a-977d-2119c0d202c0",
   "metadata": {},
   "source": [
    "Estimating $E[Y|D,W] = \\beta_0 (W) + D \\beta_1(W) = \\beta_1 + \\beta_3 W + \\beta_2 D + \\beta_4 D \\cdot W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "078807d9-0cfe-4fe7-92df-6c27416af79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "efc68e05-3fe3-4399-b293-a61694e61d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train = X_train[:,1:]\n",
    "d_train = X_train[:,0]\n",
    "X_lr = np.concatenate((w_train,d_train.reshape(d_train.shape[0],1),np.multiply(d_train[:, np.newaxis], w_train)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "16c6c20e-ddeb-418f-92c9-92853480bdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19012858925133\n",
      "[ 0.09126604 -0.29006266 -0.42020852 -0.3724348  -0.22388453  0.09206807\n",
      " -0.18419724  0.0541554   0.00745087  0.43659203 -0.14280468  0.050504\n",
      "  0.1924615 ]\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_lr,y_train)\n",
    "print(reg.intercept_)\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e736c01d-d8a0-4614-8495-cf508ddb90a0",
   "metadata": {},
   "source": [
    "$\\beta_1 = 2.2.19012858925133$ \n",
    "\n",
    "$\\beta_3 = \\begin{bmatrix}\n",
    "                0.0.09126604  \\\\\n",
    "                -0.29006266 \\\\\n",
    "                -0.42020852 \\\\\n",
    "                -0.3724348 \\\\\n",
    "                -0.22388453  \\\\\n",
    "                 0.09206807\n",
    "            \\end{bmatrix}$\n",
    "            \n",
    "$\\beta_2 = -0.18419724$\n",
    "\n",
    "$\\beta_4 = \\begin{bmatrix}\n",
    "                0.0541554 \\\\\n",
    "                0.00745087 \\\\\n",
    "                0.43659203 \\\\\n",
    "                -0.14280468 \\\\\n",
    "                0.050504 \\\\\n",
    "                0.1924615\n",
    "            \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e22b9-00da-4dc6-8924-41978340efb6",
   "metadata": {},
   "source": [
    "### Part (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4488a616-62ae-4aec-9962-d46df1393d0c",
   "metadata": {},
   "source": [
    "\n",
    "b0(w) uses subsample where everyone is control and b1(w) is where everyone is treated on Y minus the fitted values of b0(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e3b0a51-a4b0-4973-bf95-59f5d619d112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestRegressor(n_jobs=-1, random_state=31),\n",
       "             param_grid={&#x27;max_features&#x27;: array([1, 2, 3, 4, 5, 6])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestRegressor(n_jobs=-1, random_state=31),\n",
       "             param_grid={&#x27;max_features&#x27;: array([1, 2, 3, 4, 5, 6])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1, random_state=31)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1, random_state=31)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestRegressor(n_jobs=-1, random_state=31),\n",
       "             param_grid={'max_features': array([1, 2, 3, 4, 5, 6])})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "temp_df = np.concatenate((X_train,y_train.reshape(y_train.shape[0],1)),axis=1)\n",
    "ctrl_df = temp_df[temp_df[:,0] == 0]\n",
    "w_ctrl = ctrl_df[:,1:-1]\n",
    "y_ctrl = ctrl_df[:,-1]\n",
    "\n",
    "rf1 = RandomForestRegressor(n_jobs = -1, random_state=31)\n",
    "parameters = {'max_features':np.linspace(1,6,6,dtype=int)}\n",
    "b0w = GridSearchCV(rf1, parameters)\n",
    "b0w.fit(w_ctrl,y_ctrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9c7ffd3b-f8a5-4c3b-bf11-cae9dfd97c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestRegressor(n_jobs=-1, random_state=31),\n",
       "             param_grid={&#x27;max_features&#x27;: array([1, 2, 3, 4, 5, 6])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestRegressor(n_jobs=-1, random_state=31),\n",
       "             param_grid={&#x27;max_features&#x27;: array([1, 2, 3, 4, 5, 6])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1, random_state=31)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1, random_state=31)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestRegressor(n_jobs=-1, random_state=31),\n",
       "             param_grid={'max_features': array([1, 2, 3, 4, 5, 6])})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_df = temp_df[temp_df[:,0] == 1]\n",
    "d_trt = trt_df[:,0]\n",
    "w_trt = trt_df[:,1:-1]\n",
    "y_trt = trt_df[:,-1]\n",
    "\n",
    "b0w_fitted = y_trt - d_trt * b0w.predict(w_trt)\n",
    "rf2 = RandomForestRegressor(n_jobs = -1, random_state=31)\n",
    "parameters = {'max_features':np.linspace(1,6,6,dtype=int)}\n",
    "b1w = GridSearchCV(rf2, parameters)\n",
    "b1w.fit(w_trt,b0w_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "18e5a62f-1a52-460b-9974-41ae95a978ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_test = X_test[:,1:]\n",
    "d_test = X_test[:,0]\n",
    "X_lr_test = np.concatenate((w_test,d_test.reshape(d_test.shape[0],1),np.multiply(d_test[:, np.newaxis], w_test)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d939f31a-2e04-484b-8854-b8ef42673f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Functional Form Error: 1.4572430912505143\n",
      "RF Error: 1.46095396815586\n"
     ]
    }
   ],
   "source": [
    "rf_pred = b0w.predict(w_test) + d_test * b1w.predict(w_test)\n",
    "lr_pred = reg.predict(X_lr_test)\n",
    "\n",
    "print('Linear Functional Form Error:', mean_squared_error(y_test, lr_pred))\n",
    "print('RF Error:', mean_squared_error(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51899fd-2784-4e35-bbb7-b260fe5fda72",
   "metadata": {},
   "source": [
    "I would trust the random forest estimator from Part (5) more since it does not assume that the functional forms of $\\beta_0 (W)$ and $\\beta_1 (W)$ are linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c53555-1c92-4aa8-b62c-6c3cad465156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "class",
   "language": "python",
   "name": "class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
