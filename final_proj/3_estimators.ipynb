{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266720c7-42d9-4206-82a2-c96c1afc4db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from multiprocessing import cpu_count\n",
    "max_cpu = cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5e4bbea7-81d7-4180-b608-e3ac359f1581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "\n",
    "def np_standardize(arr):\n",
    "    return (arr - np.mean(arr,axis=0))/np.std(arr,axis=0)\n",
    "\n",
    "def postlassoIV_est(y,d,w,Z):\n",
    "    '''\n",
    "    Post Lasso IV Estimator based on Section 2.4 of BCCH 2015. Expects numpy arrays as arguments.\n",
    "    For our setting, we only have 1 endogenous regression X which enters as a column vector.\n",
    "    \n",
    "    Parameters:\n",
    "        y - outcome vector\n",
    "        d - endogenous regressor\n",
    "        w - exogenous regressors (excluded instruments)\n",
    "        Z - instruments for D (included instruments)\n",
    "    '''\n",
    "    Z_standard = np_standardize(Z)\n",
    "    \n",
    "    # constructing optimal instrument \\hat{D}\n",
    "    ## selecting instruments\n",
    "    lasso = LassoCV()\n",
    "    lasso.fit(np.concatenate((Z_standard,w), axis=1),d)\n",
    "    var_select = [i for i, coef in enumerate(lasso.coef_.flatten()[:Z.shape[1]]) if coef != 0]\n",
    "    Z_select = Z[:,var_select]\n",
    "    \n",
    "    ## getting \\hat{D} using fitted values of OLS of d on Z_select\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(np.concatenate((Z_select,w), axis=1),d)\n",
    "    D_hat = lr.predict(np.concatenate((Z_select,w), axis=1)).T\n",
    "    \n",
    "    # calculating IV estimator (since we are in the just identified case due to having one endogenous regressor, the\n",
    "    # standard covariance formula suffices\n",
    "    #alpha = np.linalg.inv(D_hat @ d.reshape(d.shape[0],1)) @ D_hat.T @ y\n",
    "    alpha = np.cov(D_hat,y)[0,1] / np.cov(D_hat,d)[0,1]\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "def partialw(u,w):\n",
    "    u_tilde = u - w @ np.linalg.inv(w.T @ w) @ (w.T @ u)\n",
    "    return u_tilde\n",
    "\n",
    "def postlassoIV_robusttest(y,d,w,Z,a):\n",
    "    '''\n",
    "    Sup-score statistic for testing the hypothesis \\alpha_1 = a. Robust to weak instruments.\n",
    "    Section 4.2 of BCCH 2015. Modified for scalar a.\n",
    "    '''\n",
    "    \n",
    "    # partialling out w\n",
    "    y_tilde = partialw(y,w)\n",
    "    d_tilde = partialw(d,w)\n",
    "    Z_tilde = partialw(Z,w)\n",
    "    \n",
    "    # normalizing instruments\n",
    "    Z_tilde_norm = np_standardize(Z_tilde)\n",
    "    \n",
    "    # making test statistic\n",
    "    n = y_tilde.shape[0]\n",
    "    temp_stats = np.array([])\n",
    "    for j in range(0,Z.shape[1]):\n",
    "        num = np.abs(n * np.mean((y_tilde - d_tilde * a) @ Z_tilde_norm[:,j]))\n",
    "        denom = np.sqrt(np.mean(np.square(y_tilde - d_tilde * a) @ np.square(Z_tilde_norm[:,j])))\n",
    "        temp_stats = np.append(temp_stats,num / denom)\n",
    "    \n",
    "    return temp_stats.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "25ca3df7-ad8b-4079-939f-c6b635b80597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9c691138-59a3-44b4-b7cc-d0f5846c6960",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['lsales'].to_numpy()\n",
    "d = df['lprice'].to_numpy()\n",
    "w = df.filter(regex='^cntyfe_|^timefe_').to_numpy()\n",
    "Z = df.filter(regex='^aftexpl\\\\.dist_to_ref\\\\d+').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1e13676d-9188-4406-8b10-c7e18defaf5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6128438965704044"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_1 = postlassoIV_est(y,d,w,Z)\n",
    "alpha_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d6280531-5d72-4a92-b4a8-4b46294e6eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35338.9134585225"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0\n",
    "postlassoIV_robusttest(y,d,w,Z,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b6c4c-430d-44cc-81c6-34736449134a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "class",
   "language": "python",
   "name": "class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
